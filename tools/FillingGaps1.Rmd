---
title: "Filling Gap Weeks"
author: "Ioannis Malagaris"
output:
  html_document: 
    css: style.css
    theme: NULL
    df_print: kable
    template: NULL
---

```{r setup, include=FALSE, cache.path="cache/"}
knitr::opts_chunk$set(echo = TRUE, cache.path = "cache/", dpi = 300)
library(devtools)
```



Purpose: Proper implementation of **`Filling Gaps`** functionality (Code can be
executed in project's dir).

## Setup

- After loading the data, we get variables of interest from the internal 
dataframe **`datWeeks`**.
  - The variable **`enrolled`** is the number of subjects enrolled in each week.
  - The variable **`activeDays`** is the number of active recruitment days in 
each week.  

```{r, collapse = TRUE}
load_all()
LoadData(gripsYR1, ScreenDt, Enrolled)
train <- the$datWeeks$enrolled
nonGap <- the$datWeeks$activeDays != 0
nonGapVals <- train[nonGap]
gapIdx <- which(!nonGap)
the$datWeeks[gapIdx, ]
```

We see there are 17 gap weeks. I will refer to each gap week by its order in the
dataset (or rowname) and I wont' use the variable **`week`**. i.e. I will use
 **`Week 14`** insted of **`Week 38`**.

### Calculating Sampling Weights
- I used the binomial weights used in the rest of the package while
  - The weights for all gap weeks are set to zero.
  - Weights are normalized to sum to 1.


```{r}
bnWt <- stats::dbinom(0L:51L, 51L, 0.5)
idWt <- \(t) ((0L:51L + 26L - t) %% 52L) + 1L
getWts <- \(t) (bnWt[idWt(t)] * nonGap) |> (\(x) x / sum(x))()
p <- lapply(gapIdx, getWts) |> setNames(paste("Week", gapIdx))
sapply(p, which.max)
```

The variable **`p`** is a list of 17 vectors, with each vector containing the
weights for the corresponding gap week. The output above shows which **non-gap** 
week has the highest weight for each gap week.  

### Visual Inspection of sampling weights
For visual inspection, I plot the weights for the gap weeks 20 and 28. 

```{r, out.width="100%", fig.dpi=300, fig.height=4}
pPar <- list(ylim = c(0, 0.55), type = "h", xlab = "", lwd = 2)
gPar <- list(las = 1, font.lab = 2, cex.main = 1, cex.lab = 1, cex.axis = 1,
  fig = c(0, .5, 0, 1), mar = c(1, 4, 1, 0), mgp = c(3, .8, 0), pty = "s"
)
plotWeek <- \(x, ylab = "", y = paste("Week", x)) {
  pPar[c("x", "ylab", "main")] <-  list(p[[y]], ylab, y)
  do.call(par, gPar)
  do.call(plot, pPar)
  points(x, -.01, pch = 19, col = "red")
  abline(h = c(1:5) / 10, lty = 2, col = "gray80")
}
oldPar <- par(no.readonly = TRUE)
plotWeek(21, "Sampling Weights")
gPar[c("fig", "mar",  "new")] <- list(c(.5, 1, 0, 1), mar = c(1, 3, 1, 1), TRUE)
plotWeek(28)
mtext("Weights for Filling Gaps", 3, -2, TRUE, cex = 1.1, font = 2)
mtext("Weeks", 1, -1, TRUE, font = 2)
do.call(par, oldPar)
```

We observe that there are gaps in what would have been a bell-shaped curve. Also,
in the case of **Week 20**, the weight of week 19 is very high as there are not 
other non-gap weeks in the vicinity.

\pagebreak

## Simulation Results
I will refer to the weights created above simply as **`weights`**. I run 10,000 
simulations, for each of 5 different sampling methods and I present the generated
sample's mean and CV [MEAN (SD/MEAN)] for each gap week. The five sampling method are:

- **Bootstrap**: Sample 1 value from the non-gap weeks (equal weights for all).
- **Binomial**: Sample 1 value using the weights.
- **BinomialMu3**, **BinomialMu6** and **BinomialMu9**: Mean of 3, 6, or 9 
sampled values using the weights.

The results of each method are presented as a column in the table below. The
first column is the dot product of the real sample with the corresponding 
weights of each gap week (Expected Enrollment Value). The last row is 
resulting total enrollment as [Total (SD of Total)] (reminder: init N = 18)

```{r, cache=TRUE}
len <- length(gapIdx)
wk <- seq_len(len) |> setNames(names(p))

btstrp <- \() vapply(wk, \(x) sample(nonGapVals, 1), 0L)
bnm <- \(n = 1) vapply(wk, \(x) mean(sample(train, n, FALSE, p[[x]])), .0)
list2df <- \(x) do.call(rbind, x) |> as.data.frame()

nSim <- seq_len(1e4)
dfs <- list()
dfs[["Bootstrap"]] <- lapply(nSim, \(x) btstrp()) |> list2df()
dfs[["Binom"]]     <- lapply(nSim, \(x) bnm(1L))  |> list2df()
dfs[["BinomMu3"]]  <- lapply(nSim, \(x) bnm(3L))  |> list2df()
dfs[["BinomMu6"]]  <- lapply(nSim, \(x) bnm(6L))  |> list2df()
dfs[["BinomMu9"]]  <- lapply(nSim, \(x) bnm(9L))  |> list2df()


reportMeanCVUnit <- \(x) sprintf("%5.2f (%3.1f)", mean(x), sd(x) / mean(x))
reportMeanSdUnit <- \(x) sprintf("%5.2f (%3.1f)", mean(x), sd(x))
out <- numeric(len) |> setNames(names(p))
reportMeanCV <- function(df) {
  out <- lapply(df, reportMeanCVUnit) |> cbind()
  N <- ((apply(df, 1, sum)) + 18) |> reportMeanSdUnit()
  rbind(out, N)
}
for (i in seq_len(len)) out[i] <- sum(train * p[[i]])
WtMean <- c(out, 18 + sum(out)) |> sprintf(fmt = "%5.2f", ... = _)
MeanCV <- lapply(dfs, reportMeanCV) |> as.data.frame()

cbind(WtMean, MeanCV)
```

The main takeaways from the table above are:  

- **`Bootstrap`**: assigns the same value (0.5 subjects) on all weeks regardless
of position, and variation is high (CV of 1.5).
- **`Binomial`**: Weekly means are close to the expected values, but the
variability is even higher in some cases.
- **Mean of 3,6,9 sampled values**: As we take the mean of more values, the 
variability decreases but the mean progressively deviates from the Expected Value.
  
Finally, the table below shows the 95% confidence interval for the total of
resulting enrollment (rounded to the closest integer) for each method.

```{r}
lapply(dfs, \(x) quantile(round(rowSums(x) + 18), c(.025, .5, .975))) |>
  do.call(rbind, args = _) |>
  as.data.frame()
```

Again, we observed that sampling only one value using the binomial weights is
probably not the best approach because of the high variability.



